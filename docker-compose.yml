# Docker Compose configuration for Interview AI system

services:
  # База данных
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: interview_ai
      POSTGRES_USER: interview_user
      POSTGRES_PASSWORD: ${DB_PASSWORD:-interview_pass}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./migrations:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U interview_user -d interview_ai"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Object Storage
  minio:
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://minio:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3



  # Orchestrator (FastAPI)
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://interview_user:${DB_PASSWORD:-interview_pass}@db:5432/interview_ai
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin123}
      - STT_SERVICE_URL=http://stt:8001
      - TTS_SERVICE_URL=http://tts:8002
      - SCORING_SERVICE_URL=http://scoring:8003
    # Ports removed - accessed through Caddy reverse proxy
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://orchestrator:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Speech-to-Text Service
  stt:
    build:
      context: ./stt
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://interview_user:${DB_PASSWORD:-interview_pass}@db:5432/interview_ai
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin123}
    ports:
      - "8001:8001"
    volumes:
      - whisper_cache:/root/.cache/whisper
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://stt:8001/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # LLM Service (Azure GPT-4o)
  llm:
    build:
      context: ./llm
      dockerfile: Dockerfile
    environment:
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-02-15-preview}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4o}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.1}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-2000}
    ports:
      - "8004:8004"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://llm:8004/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Avatar Service
  avatar:
    build:
      context: ./avatar
      dockerfile: Dockerfile
    environment:
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin123}
      - A2E_API_KEY=${A2E_API_KEY}
      - A2E_BASE_URL=${A2E_BASE_URL:-https://video.a2e.ai}
      - A2E_DEFAULT_AVATAR_ID=${A2E_DEFAULT_AVATAR_ID:-68af59a86eeedd0042ca7e27}
      - A2E_DEFAULT_VOICE_ID=${A2E_DEFAULT_VOICE_ID:-66d3f6a704d077b1432fb7d3}
      - A2E_DEFAULT_SPEECH_RATE=${A2E_DEFAULT_SPEECH_RATE:-1.5}
      - A2E_DEFAULT_RESOLUTION=${A2E_DEFAULT_RESOLUTION:-720}  # 1:1 format (720x720)
    ports:
      - "8005:8005"
    depends_on:
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://avatar:8005/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Scoring Service (LLM)
  scoring:
    build:
      context: ./scoring
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://interview_user:${DB_PASSWORD:-interview_pass}@db:5432/interview_ai
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-02-15-preview}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4o}
    ports:
      - "8003:8003"
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://scoring:8003/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Frontend (Vue/React)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - VITE_API_URL=/api
    depends_on:
      - orchestrator
    healthcheck:
      test: ["CMD", "curl", "-f", "http://frontend:3000"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Caddy Reverse Proxy with automatic SSL
  caddy:
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - caddy_logs:/var/log/caddy
    extra_hosts:
      - "moretech2025clvb.ru:127.0.0.1"
    depends_on:
      - frontend
      - orchestrator
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: moretech2025-redis-1
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  minio_data:
  whisper_cache:
  redis_data:
  caddy_data:
  caddy_config:
  caddy_logs:
